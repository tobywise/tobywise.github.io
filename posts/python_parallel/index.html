<!doctype html><html><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><script src=https://code.jquery.com/jquery-3.4.1.slim.min.js integrity=sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js integrity=sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js integrity=sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6 crossorigin=anonymous></script>
<link href="https://fonts.googleapis.com/css?family=Rubik:100,200,300,400" rel=stylesheet><link href="https://fonts.googleapis.com/css?family=Roboto:100,200,300,400" rel=stylesheet><link rel=preconnect href=https://fonts.gstatic.com><link rel=preconnect href=https://fonts.gstatic.com><link href="https://fonts.googleapis.com/css2?family=Rufina:wght@700&family=Work+Sans:wght@100;300;400;500;600;700&Lato:ital,wght@0,100;0,300;0,400;0,700;0,900;1,100;1,300;1,400;1,700display=swap" rel=stylesheet><link rel=stylesheet type=text/css href=/css/bootstrap.min.css><link rel=stylesheet type=text/css href=/css/style.css><title>TOBY WISE | How to make Python code faster</title></head><body><nav class="navbar sticky-top navbar-expand-lg navbar-light bg-light"><div class=container><a class="navbar-brand text-dark" href=/><div>TOBY WISE</div></a><button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarNav aria-controls=navbarNav aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><ul class="collapse navbar-collapse ml-auto w-100 justify-content-end" id=navbarNav style=margin:auto><a class="nav-item nav-link justify-content-end" href=/><a class=menu-entries href=http://localhost:1313/>Home</a></a>
<a class="nav-item nav-link justify-content-end" href=/posts/><a class=menu-entries href=http://localhost:1313/posts/>Posts</a></a>
<a class="nav-item nav-link justify-content-end" href=/about/><a class=menu-entries href=http://localhost:1313/about/>About</a></a>
<a class="nav-item nav-link justify-content-end" href=/cv/><a class=menu-entries href=http://localhost:1313/cv/>CV</a></a>
<a class="nav-item nav-link justify-content-end" href=/publications/><a class=menu-entries href=http://localhost:1313/publications/>Publications</a></a>
<a class="nav-item nav-link justify-content-end" href=/research/><a class=menu-entries href=http://localhost:1313/research/>Research</a></a>
<a class="nav-item nav-link justify-content-end" href=http://github.com/tobywise><a class=menu-entries href=http://github.com/tobywise><i data-feather=github></i></a></a>
<a class="nav-item nav-link justify-content-end" href=https://osf.io/dnwpx/><a class=menu-entries href=https://osf.io/dnwpx/><i class="ai ai-osf ai-2x" style=font-size:1.7em></i></a></a>
<a class="nav-item nav-link justify-content-end" href="https://scholar.google.co.uk/citations?user=_PD-jwIAAAAJ&hl=en"><a class=menu-entries href="https://scholar.google.co.uk/citations?user=_PD-jwIAAAAJ&hl=en"><i class="ai ai-google-scholar ai-2x" style=font-size:1.7em></i></a></a>
<a class="nav-item nav-link justify-content-end" href=https://twitter.com/toby_wise><a class=menu-entries href=https://twitter.com/toby_wise><i data-feather=twitter></i></a></a></ul></div></div></nav><div id=content><div class="container w-100 text-dark"><div class=container-bg><h1>How to make Python code faster</h1><i data-feather=calendar></i>
<time datetime=2021-03-28>Mar 28, 2021</time>
<i data-feather=tag></i>
<a class="btn btn-sm btn-outline-primary text-dark tag-btn" href=http://localhost:1313/tags/blog>blog</a>
<a class="btn btn-sm btn-outline-primary text-dark tag-btn" href=http://localhost:1313/tags/coding>coding</a><br><br><p>As a fanatical Python enthusiast, I have frequently tried to convert Matlab users to my preferred language. Alongside common complaints such as <em>&ldquo;Please stop bothering me&rdquo;</em> and <em>&ldquo;Why do you keep going on about this&rdquo;</em>, one that I&rsquo;ve heard a few times is <em>&ldquo;Yeah Python seems great, but it&rsquo;s so slow&rdquo;</em>.</p><p>Sadly, this is correct - Python is <a href=https://medium.com/swlh/a-performance-comparison-between-c-java-and-python-df3890545f6d>slow</a> compared to other languages, including Matlab. While arguably it makes up for this in <a href=https://medium.com/pyslackers/yes-python-is-slow-and-i-dont-care-13763980b5a1>other ways</a>, speed is still important for many tasks.</p><p>One obvious way to speed up computation in any language is to use your computer&rsquo;s full processing power for the task, using parallel processing to use more than just a single core to rapidly decrease computation times. However, parallelisation in Python is not necessarily straightforward. Another avenue is to translate Python code to faster C code, however this can also be tricky.</p><p>This is something I&rsquo;ve spent a fair bit of time messing around with, and while I am by no means an expert I thought it might be helpful to write down what I&rsquo;ve learnt, both for my future self and others out there who might want to speed up their Python code. This won&rsquo;t cover parallel processing on clusters, the focus here is on single-machine parallelisation.</p><h2 id=background-on-parallel-processing>Background on parallel processing</h2><p>Parallel processing essentially involves breaking a big job into chunks, sending each chunk to a single CPU core to run, and then collecting the results. This can be useful, for example, if you have a big for loop. Say you need to loop through 10 items and run some intensive processing on each one, taking ~60 seconds. One option would be to run through item by item in serial, which would take around 10 minutes. Alternatively, if you have 10 CPU cores, you could send each iteration to a separate core and have them all run at once. This would get the same job done in about 1 minute, giving you a 10x speedup (the speedup isn&rsquo;t always this clear in reality, more on that later).</p><h3 id=basic-principles>Basic principles</h3><p>There are a few important things to consider when trying to parallelise any code.</p><h4 id=beware-of-race-conditions>Beware of &ldquo;race conditions&rdquo;</h4><p>Sometimes you might want to iteratively run code that modifies a shared variable. For example, say you have some value you want to update on each iteration:</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">3
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">4
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">5
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>value <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>100</span>):
</span></span><span style=display:flex><span>    value <span style=color:#f92672>+=</span> i
</span></span><span style=display:flex><span>    do_something(value)
</span></span></code></pre></td></tr></table></div></div><p>Running this in serial is straightforward - each iteration will run <code>do_something()</code> with a value of <code>value</code> that is <code>i</code> greater than the previous iteration. However, in parallel this could cause problems - if dispatched to different CPU cores, each process is not gauranteed to finish in the same order it would if run in serial. In this toy example, this could mean that <code>do_something()</code> is being run with a <code>value</code> that is different to what it would be if run in serial. This might not necessarily be a problem, it&rsquo;ll depend on the use.</p><blockquote class=twitter-tweet><p lang=en dir=ltr>- "What do we want?"<br>- "Now!"<br>- "When do we want it?"<br>- "Fewer race conditions!"</p>&mdash; Anna Melzer (@wellendonner) <a href="https://twitter.com/wellendonner/status/677456039705501696?ref_src=twsrc%5Etfw">December 17, 2015</a></blockquote><script async src=https://platform.twitter.com/widgets.js></script><h4 id=the-costs-of-parallisation>The costs of parallisation</h4><p>Running processing in parallel is rarely free. The process of dispatching a process to execute the code and transferring the necessary data to that process takes time (known as <strong>overhead</strong>) - this will sometimes be a bigger issue if there is more data involved which needs to be transferred to each new parallel process. This results in a fairly important rule for running analyses in parallel:</p><p><strong>Do not parallelise small chunks of processing</strong>.</p><p>The reason for this is that the costs of executing code in parallel stay relatively constant regardless of the computational requirements of the code itself. For example, say the cost of executing a single chunck of code in parallel (in terms of the startup/data transfer cost) is 2 seconds. Going back to our earlier example of a process that takes 60 seconds, this means that each of the 10 processes will cost an extra 2 seconds relative to running the code in serial. This is still a great speedup - it&rsquo;ll now be 62 seconds rather than 10 minutes.</p><p>However if our processing is pretty fast, say 0.5 seconds rather than 60 seconds, things change. We still have the 2 second parallelisation cost, so each process takes 2.5 seconds to run, compared to 0.5 seconds in serial. Therefore the time taken for a parallel version is 2.5 seconds, compared to 5 seconds (10 x 0.5 seconds) for the serial version. It&rsquo;s still a speedup, but it&rsquo;s nowhere near as big a speedup as we get with the more time-consuming process.</p><p>In practice, this means that if for example you want to process data for 10 subjects, it&rsquo;s generally better to process each subject in its entirety within a separate process, rather than for example running each individual processing step in parallel.</p><h4 id=memory-can-be-a-limiting-factor>Memory can be a limiting factor</h4><p>Even if your computer has 64 cores, this doesn&rsquo;t necessarily mean you&rsquo;ll have the capacity to process 64 things at once. It&rsquo;s important to bear in mind the fact that your memory usage will often increase in line with the number of parallel processes you&rsquo;re running. For example, if you&rsquo;re processing multiple subjects in serial, you only need to load one subject&rsquo;s data into memory at a time. In contrast, if you&rsquo;re running 64 at once, this means you&rsquo;ll need to load 64 subjects&rsquo; data in at once! One subject might be 10GB if you&rsquo;re dealing with neuroimaging data, however 64 subjects is going to need 640GB which you&rsquo;re unlikely to have access to. There are ways around this for certain situations (such as using Numpy&rsquo;s <a href=https://joblib.readthedocs.io/en/latest/auto_examples/parallel_memmap.html>memmapping</a>), however there&rsquo;s no way to avoid this limitation entirely.</p><h3 id=implementing-parallel-processing-in-python>Implementing parallel processing in Python</h3><p>There are a range of parallel processing packages available for Python. It even comes with one built-in, called <code>multiprocessing</code>. In my experience, I&rsquo;ve generally found <code>multiprocessing</code> to be fairly powerful but also a little awkward to work with. I will therefore focus on the one I tend to use the most.</p><h3 id=joblib-parallelisation>Joblib parallelisation</h3><p><a href=https://joblib.readthedocs.io/en/latest/>Joblib</a> does a few things, one of which is implementing straightforward parallel processing. Joblib has thorough <a href=https://joblib.readthedocs.io/en/latest/parallel.html>documentation</a>, so I&rsquo;ll just cover the basics here.</p><p>The idea of the parallel methods in Joblib is to take a list of items that will be processed, split it into chunks, and then run the processing on each one. One nice feature of Joblib&rsquo;s functions is that it maintains the order of its inputs, so you avoid them coming back in a different order than the one in which they were sent.</p><p>The Joblib interface is based around the <code>Parallel</code> and <code>delayed</code> functions. The <code>Parallel</code> function enables your custom function to be run in parallel. The <code>delayed</code> function might seem a little confusing - essentially all this does is tell Python to hold off on running the requested code until it&rsquo;s able to do it in one of the parallel processes.</p><p>This means you end up with something like:</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">3
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">4
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">5
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">6
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> joblib <span style=color:#f92672>import</span> Parallel, delayed
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>example_func</span>(X):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> np<span style=color:#f92672>.</span>sqrt(X)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Parallel(n_jobs<span style=color:#f92672>=</span><span style=color:#ae81ff>6</span>)(delayed(example_func)(i) <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> np<span style=color:#f92672>.</span>arange(<span style=color:#ae81ff>100</span>))
</span></span></code></pre></td></tr></table></div></div><p>This would return the square root of every item between 0 and 100. This syntax might look a little strange, so let&rsquo;s break down what this is doing a little:</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>example_func</span>(X):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> np<span style=color:#f92672>.</span>sqrt(X)
</span></span></code></pre></td></tr></table></div></div><p>This is the function we want to run on every item in a list in parallel.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>Parallel(n_jobs<span style=color:#f92672>=</span><span style=color:#ae81ff>6</span>)
</span></span></code></pre></div><p>This function call tells Python that we want to run something in parallel, and that we want it split across 6 different processes (this should be at most the number of CPUs your system has access to.)</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>(delayed(example_func)(i) <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> np<span style=color:#f92672>.</span>arange(<span style=color:#ae81ff>100</span>))
</span></span></code></pre></div><p>This is a list comprehension (i.e. <code>(function(item) for item in list</code>).</p><p>For each item in the list (for each <code>i</code> in <code>np.arange(100)</code>), we are doing:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>delayed(example_func)(i)
</span></span></code></pre></div><p>This is first using <code>delayed(example_func)</code> to create a &ldquo;delayed execution&rdquo; version of our example function (as mentioned earlier, this just ensures it is run by the parallel process, rather than being run immediately). Adding <code>(i)</code> is then just calling this function with everything in brackets as its arguments, in this case it&rsquo;s just <code>i</code> that we&rsquo;re feeding in.</p><p>Using this simple method, it&rsquo;s easy to run things in parallel without having to mess around with manually setting up pools of workers etc., as is necessary when using <code>multiprocessing</code>. This basic workflow can be extended to support more complicated requirements, e.g. shared memory, as described in the <a href=https://joblib.readthedocs.io/en/latest/parallel.html>documentation</a></p><h2 id=optimising-python-for-speed>Optimising Python for speed</h2><p>You don&rsquo;t necessarily need to run you code in parallel to achieve significant speedups. If you&rsquo;re manipulating data in the form of NumPy arrays, there are a couple of other methods that can be effective.</p><h3 id=vectorisation>Vectorisation</h3><p>I won&rsquo;t go into detail on this because it&rsquo;s a fairly fundamental aspect of NumPy that is covered extensively <a href=https://learning.oreilly.com/library/view/python-for-data/9781449323592/ch04.html>elsewhere</a>.</p><p>Essentially, <code>for</code> loops should be avoided when manipulating NumPy arrays. Instead, vectorised operations should be used. As an example, say you want to sum the elements of two columns in an array, you could do it like this:</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">3
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">4
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>x <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>random<span style=color:#f92672>.</span>randn(<span style=color:#ae81ff>20</span>, <span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>sums <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(x<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>0</span>]):
</span></span><span style=display:flex><span>    sums<span style=color:#f92672>.</span>append(x[i, <span style=color:#ae81ff>0</span>] <span style=color:#f92672>+</span> x[i, <span style=color:#ae81ff>1</span>])
</span></span></code></pre></td></tr></table></div></div><p>This approach of looping over every element is <em>slow</em> and should be avoided. Instead, you can use vectorized operations, for example:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>sums <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>sum(x, axis<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span></code></pre></div><p>This vectorises the <code>sum</code> operation across the desired axis. Rather than summing each element individaully, it magically does the whole thing at once through clever methods that I do not understand. The effect is that this is MUCH faster - as shown below.</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">3
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">4
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">5
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">6
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">7
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>X <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>random<span style=color:#f92672>.</span>randn(<span style=color:#ae81ff>200000</span>, <span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>%</span>timeit slow_sum(X)
</span></span><span style=display:flex><span><span style=color:#ae81ff>116</span> ms <span style=color:#960050;background-color:#1e0010>±</span> <span style=color:#ae81ff>3.81</span> ms per loop (mean <span style=color:#960050;background-color:#1e0010>±</span> std<span style=color:#f92672>.</span> dev<span style=color:#f92672>.</span> of <span style=color:#ae81ff>7</span> runs, <span style=color:#ae81ff>10</span> loops each)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>%</span>timeit fast_sum(X)
</span></span><span style=display:flex><span><span style=color:#ae81ff>3.23</span> ms <span style=color:#960050;background-color:#1e0010>±</span> <span style=color:#ae81ff>214</span> µs per loop (mean <span style=color:#960050;background-color:#1e0010>±</span> std<span style=color:#f92672>.</span> dev<span style=color:#f92672>.</span> of <span style=color:#ae81ff>7</span> runs, <span style=color:#ae81ff>100</span> loops each)
</span></span></code></pre></td></tr></table></div></div><h3 id=numba>Numba</h3><p>Even when taking full advantage of Numpy&rsquo;s capabilities, it&rsquo;s not always possible to achieve the same speed as other languages. It&rsquo;s also not always possible to vectorise operations fully, meaning you&rsquo;ll be reliant on <code>for</code> loops, which (as shown above) are <em>very</em> slow in Python.</p><p>The reason for Python&rsquo;s speed is that it&rsquo;s a dynamically-typed, interactive language. This contrasts with other languages (e.g. C++). These are typically compiled rather than dynamic - this means that rather than being interpreted and run on the fly, the code is compiled to machine code (very low-level functions) in advance. This means there isn&rsquo;t an interpeter having to figure out what to do on every line, speeding things up massively. These languages also generally use static typing. In Python, you don&rsquo;t need to define the type of your variables. For example:</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">3
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>a <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>b <span style=color:#f92672>=</span> <span style=color:#ae81ff>2.5</span>
</span></span><span style=display:flex><span>c <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;hello&#34;</span>
</span></span></code></pre></td></tr></table></div></div><p>Python will figure out that <code>a</code> is an <code>int</code>, <code>b</code> is a <code>float</code>, and <code>c</code> is a <code>str</code> for you. In other languages, you can&rsquo;t do this - you need to tell the compiler what type each variable is (and depending on the language perhaps other properties, such as whether a number will be positive or negative). This means that Python has to constantly figure out what type a variable is, slowing things down.</p><p>To get around this, packages have been developed that translate your Python code to a faster language (generally C++), allowing you to use this accelerated implementation instead of the pure Python version. One that I&rsquo;ve used a lot for array-based processing is <a href=https://numba.pydata.org/>Numba</a>. Numba essentially implements Numpy&rsquo;s functionality, but compiles the code you write to C++ when it is run, speeding things up substantially.</p><p>Numba uses &ldquo;just in time&rdquo; compilation - that is, it compiles the functions when they&rsquo;re run. This is implemented using decorators <code>@jit</code> and <code>@njit</code>. For example:</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">3
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">4
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">5
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">6
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">7
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">8
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Pure python</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>do_something</span>(X, Y):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> X <span style=color:#f92672>+</span> np<span style=color:#f92672>.</span>exp(Y)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Numba version</span>
</span></span><span style=display:flex><span><span style=color:#a6e22e>@njit</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>do_something</span>(X):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> X <span style=color:#f92672>+</span> np<span style=color:#f92672>.</span>exp(Y)
</span></span></code></pre></td></tr></table></div></div><p>The code in the function itself doesn&rsquo;t necessarily change (although it will sometimes have to), it just gets compiled to a faster language.</p><p>One important thing to know when using Numba is that it&rsquo;s normally best to avoid using <code>@jit</code> and use <code>@njit</code> instead. The <code>@njit</code> decorator does not allow any code within the function to run as pure Python code, whereas the <code>@jit</code> decorator will compile the lines it is able to and leave the rest as pure Python - this means it might end up jumping between optimised and non-optimised code, delivering no speedup whatsoever.</p><p>Here&rsquo;s an example of the speedup that can be achieved:</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">15
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">16
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">17
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">18
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">19
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">20
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">21
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">22
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">23
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> numba <span style=color:#f92672>import</span> njit
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>X <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>random<span style=color:#f92672>.</span>randn(<span style=color:#ae81ff>500</span>)
</span></span><span style=display:flex><span>Y <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>random<span style=color:#f92672>.</span>randn(<span style=color:#ae81ff>500</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>example_func_python</span>(X, Y):
</span></span><span style=display:flex><span>    out <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> a <span style=color:#f92672>in</span> range(X<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>0</span>]):
</span></span><span style=display:flex><span>        results <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>zeros(<span style=color:#ae81ff>6</span>)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> b <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>6</span>):
</span></span><span style=display:flex><span>            results[b] <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>dot(np<span style=color:#f92672>.</span>ones(X<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>0</span>]), Y <span style=color:#f92672>+</span> <span style=color:#ae81ff>0.8</span><span style=color:#f92672>*</span>X)
</span></span><span style=display:flex><span>        out<span style=color:#f92672>.</span>append(results)                   
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> out
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#a6e22e>@njit</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>example_func_numba</span>(X, Y):
</span></span><span style=display:flex><span>    out <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> a <span style=color:#f92672>in</span> range(X<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>0</span>]):
</span></span><span style=display:flex><span>        results <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>zeros(<span style=color:#ae81ff>6</span>)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> b <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>6</span>):
</span></span><span style=display:flex><span>            results[b] <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>dot(np<span style=color:#f92672>.</span>ones(X<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>0</span>]), Y <span style=color:#f92672>+</span> <span style=color:#ae81ff>0.8</span><span style=color:#f92672>*</span>X)
</span></span><span style=display:flex><span>        out<span style=color:#f92672>.</span>append(results)                   
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> out
</span></span></code></pre></td></tr></table></div></div><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">3
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">4
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">5
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">6
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">7
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>%</span>timeit example_func_python(X, Y)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>20.8</span> ms <span style=color:#960050;background-color:#1e0010>±</span> <span style=color:#ae81ff>886</span> µs per loop (mean <span style=color:#960050;background-color:#1e0010>±</span> std<span style=color:#f92672>.</span> dev<span style=color:#f92672>.</span> of <span style=color:#ae81ff>7</span> runs, <span style=color:#ae81ff>10</span> loops each)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>%</span>timeit example_func_numba(X, Y)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>2.11</span> ms <span style=color:#960050;background-color:#1e0010>±</span> <span style=color:#ae81ff>132</span> µs per loop (mean <span style=color:#960050;background-color:#1e0010>±</span> std<span style=color:#f92672>.</span> dev<span style=color:#f92672>.</span> of <span style=color:#ae81ff>7</span> runs, <span style=color:#ae81ff>1</span> loop each)
</span></span></code></pre></td></tr></table></div></div><p>That&rsquo;s a roughly 10x speedup, without any changes to the code except the addition of the <code>@njit</code> decorator (if you try this yourself, it&rsquo;s worth noting that the first time you run any <code>@njit</code>ed function it&rsquo;ll be slightly slower due to the intiial compilation).</p><p>One thing you might notice is that there are a lot of <code>for</code> loops going on here. <strong>This is the kind of thing that Numba really helps with</strong>. While <code>for</code> loops are slow in pure Python, they&rsquo;re super fast in Numba&rsquo;s optimised code. While you can often vectorise operations in Numpy, sometimes there&rsquo;s no way to avoid looping, and this is where Numba really speeds things up.</p><h3 id=parallelisation-within-numba>Parallelisation within Numba</h3><p>Numba also provides the ability to parallelise the optimised code, without the need to mess with any additional packages. This is achieved by simply using <code>@njit(parallel=True)</code> and changing any <code>range()</code> function used for looping to Numba&rsquo;s <code>prange()</code> function.</p><p>However, in reality this is often not massively useful because of the costs to parallelisation mentioned above. Numba will be parallelising very small chunks of code, and so the performance gain isn&rsquo;t as great as you might hope. For example:</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> numba <span style=color:#f92672>import</span> njit, prange
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#a6e22e>@njit</span>(parallel<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>example_func_numba</span>(X, Y):
</span></span><span style=display:flex><span>    out <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> a <span style=color:#f92672>in</span> range(X<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>0</span>]):
</span></span><span style=display:flex><span>        results <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>zeros(<span style=color:#ae81ff>6</span>)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> b <span style=color:#f92672>in</span> prange(<span style=color:#ae81ff>6</span>):  <span style=color:#75715e># &lt;&lt;&lt;PARALLEL LOOP</span>
</span></span><span style=display:flex><span>            results[b] <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>dot(np<span style=color:#f92672>.</span>ones(X<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>0</span>]), Y <span style=color:#f92672>+</span> <span style=color:#ae81ff>0.8</span><span style=color:#f92672>*</span>X)
</span></span><span style=display:flex><span>        out<span style=color:#f92672>.</span>append(results)                   
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> out
</span></span></code></pre></td></tr></table></div></div><p>Here I&rsquo;ve asked one of the for loops to run in parallel - this is looping over 6 values, so in principle (assuming we have at least 6 cores), we should see a 6x speedup. However this isn&rsquo;t what we get in practice:</p><p align=center><img src=../../img/parallel_serial.png></p><p>With smaller array sizes, the parallel version is over 8x <em>slower</em> than the serial version. It&rsquo;s only when we get to fairly large arrays that the parallel version overtakes the serial version.</p><p>So why is this? With less data, the line that is being parallelised (<code>results[b] = np.dot(np.ones(X.shape[0]), Y + 0.8*X)</code>) is not particularly computationally expensive, becoming much more demanding as the array size increases. With a small array, we&rsquo;re spending a lot of time on the setting up of the parallel execution, but very little time running the code, so it ends up making things slower. As the cost of the computation itself increases, the cost of the parallelisation becomes relatively small in comparison, and parallel processing starts to make things faster.</p><h2 id=things-to-be-aware-of>Things to be aware of</h2><p>There are a few things that you should be aware of when implementing parallel processing in Python.</p><h3 id=pickling>Pickling</h3><p>Certain parallel processing packages (such as the built-in <code>multiprocessing</code> one) require functions to be <a href=https://docs.python.org/3/library/pickle.html>pickleable</a> (i.e. serialised) in order to be parallelised. This can be difficult with certain functions.</p><h3 id=using-parallel-operations-on-windows>Using parallel operations on Windows</h3><p>Most parallel operations will typically not work within the context of an interactive session on Windows (this generally isn&rsquo;t a problem on Linux/Mac OS). This is a little annoying, and the only way to get parallel operations working on Windows is to ensure your code is within the <code>__main__</code> block within a script. More info on this is available <a href=https://stackoverflow.com/questions/20222534/python-multiprocessing-on-windows-if-name-main>here</a>.</p><h3 id=inbuilt-parallel-operations>Inbuilt parallel operations</h3><p>Some NumPy functions are pre-optimised, using fast C++ routines to perform calculations (for example matrix multiplication). Depending on the libraries you&rsquo;ve got NumPy linked to, and the way your system is set up, these might be parallelising their calculations without you knowing.</p><p>Unfortunately, this can interfere with your own attempts to set up parallel workflows, as I have found out (after spending about a day trying to figure out why my beautiful, optimised, parallelised code wasn&rsquo;t running any faster). You might, for example, have 4 cores available so you split your processing into 4 streams, each of which is run in a separate process. However, each processing stream involves matrix multiplication, and NumPy itself then tries to use all the 4 cores on your system to run this. So you have 4 processes, each of which is trying to itself use the 4 available cores. This ends up making a mess of everything. Adding the following (or a subset of it, depending on the libraries you&rsquo;re using) <strong>before</strong> importing NumPy will ensure that it only tries to use a single core:</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">3
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">4
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">5
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> os
</span></span><span style=display:flex><span>os<span style=color:#f92672>.</span>environ[<span style=color:#e6db74>&#34;MKL_NUM_THREADS&#34;</span>] <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;1&#34;</span> 
</span></span><span style=display:flex><span>os<span style=color:#f92672>.</span>environ[<span style=color:#e6db74>&#34;NUMEXPR_NUM_THREADS&#34;</span>] <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;1&#34;</span> 
</span></span><span style=display:flex><span>os<span style=color:#f92672>.</span>environ[<span style=color:#e6db74>&#34;OPENBLAS_NUM_THREADS&#34;</span>] <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;1&#34;</span>
</span></span><span style=display:flex><span>os<span style=color:#f92672>.</span>environ[<span style=color:#e6db74>&#34;OMP_NUM_THREADS&#34;</span>] <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;1&#34;</span> 
</span></span></code></pre></td></tr></table></div></div><h3 id=other-frameworks-for-speeding-up-python-code>Other frameworks for speeding up Python code</h3><p>I&rsquo;ve only covered a limited number of available frameworks here. There are a multitude of others available about there for optimisation (e.g. Cython), converting numpy functions to compiled computational graphs (e.g. Jax), and advanced parallel processing (e.g. Dask).</p><p>Thanks for reading, and I hope this might help someone make their code a little faster!</p></div></div></div><br><br><script src=/js/feather.min.js></script>
<script>feather.replace()</script><link rel=stylesheet href=https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css></body></html>